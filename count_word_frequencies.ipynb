{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import plotly.express as px\n",
    "import glob\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Häufigkeiten der Wortfelder für Romankorpus berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatisiertes Korpus einlesen\n",
    "df = pd.read_csv(\"data/roman_corpus_lemmatisiert.csv\", sep=\";\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen wiederherstellen (weil als String eingelesen)\n",
    "for i in tqdm(range(len(df))):\n",
    "    lemmas = str(df[\"all_lemmas\"].loc[i])\n",
    "    lemmas = re.sub(r\"'\", \"\", lemmas)\n",
    "    lemmas = re.sub(r\"\\[\", \"\", lemmas)\n",
    "    lemmas = re.sub(r\"\\]\", \"\", lemmas)\n",
    "    lemmas = lemmas.split(\", \")\n",
    "    df[\"all_lemmas\"].loc[i] = lemmas\n",
    "    #print(type(lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung der Anzahl jeweiliger Wortfelder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting wordlist\n",
    "def process_wordlist(Pfad):\n",
    "    wordlist_df = pd.read_csv(Pfad, sep=\";\", encoding=\"utf-8\")\n",
    "    words = list(wordlist_df[\"Word\"])\n",
    "    \n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_lemmalist(wordlist, counter):\n",
    "    words_counter = 0\n",
    "    for word in wordlist:\n",
    "        words_counter += counter[word]\n",
    "    return words_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/Wordlists_from_fasttext/*cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    \n",
    "    wortfeld = file.split(\"/\")[1].split(\"_\")[0]\n",
    "    #print(wortfeld)\n",
    "    print(\"Prozessiere: \" + wortfeld + \" \" + str(files.index(file)))\n",
    "    \n",
    "    \n",
    "    string = \"anteil_\" + wortfeld\n",
    "    df[string] = 0\n",
    "    wortfeld_woerter = process_wordlist(file)\n",
    "    for i in tqdm(range(len(df))):\n",
    "        lemmas = df[\"all_lemmas\"].loc[i]\n",
    "        all_words_count = len(lemmas)\n",
    "        counter = Counter(lemmas)\n",
    "    \n",
    "        wortfeld_counter = count_words_in_lemmalist(wortfeld_woerter, counter)\n",
    "        df[string].loc[i] = wortfeld_counter/all_words_count\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Häufigkeiten für konkret/abstrakt summieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"anteil_konkret\"] = df[\"anteil_Ornamente\"] + df[\"anteil_Dekorationsgegenstaende\"] \\\n",
    "                    + df[\"anteil_Bauwerke\"] + df[\"anteil_Gebaeudeteile\"] + \\\n",
    "                    df[\"anteil_Zimmer\"] + df[\"anteil_Moebel\"] + \\\n",
    "                    df[\"anteil_Heimtextilien\"] + df[\"anteil_Haushaltsgegenstaende\"] + \\\n",
    "                    df[\"anteil_Kleidung\"] + df[\"anteil_Kleidungsteile\"] + \\\n",
    "                    df[\"anteil_Aufmachung\"] + df[\"anteil_aussehensspezifisch\"] \\\n",
    "                    + df[\"anteil_Taschen\"] + df[\"anteil_Stoffe\"] +   \\\n",
    "                    df[\"anteil_formspezifisch\"] + \\\n",
    "                    df[\"anteil_helligkeitsspezifisch\"] + df[\"anteil_oberflaechenspezifisch\"] + \\\n",
    "                    df[\"anteil_Holz\"] +df[\"anteil_Koerperteile\"] + df[\"anteil_Farben\"] + \\\n",
    "                    df[\"anteil_Gruenflaechen\"] + df[\"anteil_Gerueche\"] + df[\"anteil_Pflanzen\"] + \\\n",
    "                    df[\"anteil_Pflanzenteile\"] + df[\"anteil_Gartenanlagen\"] + \\\n",
    "                    df[\"anteil_Wege\"] + df[\"anteil_Waelder\"] + \\\n",
    "                    df[\"anteil_Bilder\"] + df[\"anteil_Schmuck\"]+ df[\"anteil_Kunstobjekte\"] + \\\n",
    "                    df[\"anteil_Muster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"anteil_abstrakt\"] = df[\"anteil_Emotionen\"] + df[\"anteil_Charaktereigenschaften\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung Anzahl einiger Grundwörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grundfarben = [\"rot\", \"blau\", \"grün\"]\n",
    "Grundkleidung = [\"Kleid\", \"Mantel\", \"Hut\"]\n",
    "Grundkoerperteile = [\"Finger\", \"Ohr\", \"Nase\"]\n",
    "wortfelder = [Grundfarben, Grundkleidung, Grundkoerperteile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wortfeld in wortfelder:\n",
    "   \n",
    "    string = \"anteil_\" + str(wortfeld)\n",
    "    \n",
    "    df[string] = 0\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        lemmas = df[\"all_lemmas\"].loc[i]\n",
    "        \n",
    "        all_words_count = len(lemmas)\n",
    "        counter = Counter(lemmas)\n",
    "    \n",
    "        wortfeld_counter = count_words_in_lemmalist(wortfeld, counter)\n",
    "        df[string].loc[i] = wortfeld_counter/all_words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern als csv-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_lemmas = df.copy()\n",
    "df_without_lemmas = df_without_lemmas.drop(columns=[\"all_lemmas\"])\n",
    "df_without_lemmas.to_csv(\"data/roman_corpus_word_frequencies.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Häufigkeiten der Wortgruppen \"abstrakt\" und \"konkret\" für Romankorpus berechnen unter Berücksichtigung der Redeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "konkrete_wortfelder = [\"Ornamente\", \"Dekorationsgegenstaende\", \"Bauwerke\", \"Gebaeudeteile\",  \"Zimmer\",\\\n",
    "                       \"Moebel\", \"Heimtextilien\", \"Haushaltsgegenstaende\", \"Kleidung\", \"Kleidungsteile\" ,\\\n",
    "                       \"Aufmachung\", \"aussehensspezifisch\", \"Taschen\", \"Stoffe\", \"formspezifisch\", \\\n",
    "                       \"helligkeitsspezifisch\", \"oberflaechenspezifisch\", \"Koerperteile\", \"Farben\",\\\n",
    "                      \"Pflanzen\", \"Pflanzenteile\", \"Schmuck\", \"Gruenflaechen\", \"Bilder\", \"Gartenanlagen\",\\\n",
    "                      \"Waelder\", \"Kunstobjekte\", \"Wege\", \"Gerueche\", \"Muster\", \"Holz\"] \n",
    "konkrete_woerter = []\n",
    "for wortfeld in konkrete_wortfelder:\n",
    "    file = \"data/Wordlists_from_fasttext/\" + wortfeld + \"_from_fasttext_cleaned.csv\"\n",
    "    konkrete_woerter += process_wordlist(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charaktereigenschaften = process_wordlist(\"data/Wordlists_from_fasttext/Charaktereigenschaften_from_fasttext_cleaned.csv\")\n",
    "emotionen = process_wordlist(\"data/Wordlists_from_fasttext/Emotionen_from_fasttext_cleaned.csv\")\n",
    "abstrakte_woerter = charaktereigenschaften + emotionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary erstellen, in dem Wörter aus Wortlisten nach abstrakt/konkret\n",
    "\n",
    "def def_value():\n",
    "    return \"Not Present\"\n",
    "words_dict = defaultdict(def_value)\n",
    "for word in konkrete_woerter:\n",
    "    words_dict[word] = \"konkr\"\n",
    "\n",
    "for word in abstrakte_woerter:\n",
    "    words_dict[word] = \"abst\"\n",
    "#words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wortfelder = [\"Ornamente\", \"Dekorationsgegenstaende\", \"Bauwerke\", \"Gebaeudeteile\",  \"Zimmer\",\\\n",
    "                       \"Moebel\", \"Heimtextilien\", \"Haushaltsgegenstaende\", \"Kleidung\", \"Kleidungsteile\" ,\\\n",
    "                       \"Aufmachung\", \"aussehensspezifisch\", \"Taschen\", \"Stoffe\", \"formspezifisch\", \\\n",
    "                       \"helligkeitsspezifisch\", \"oberflaechenspezifisch\", \"Koerperteile\", \"Farben\",\\\n",
    "                      \"Pflanzen\", \"Pflanzenteile\", \"Schmuck\", \"Gruenflaechen\", \"Bilder\", \"Gartenanlagen\",\\\n",
    "                      \"Waelder\", \"Kunstobjekte\", \"Wege\", \"Gerueche\", \"Muster\", \"Holz\", \"Charaktereigenschaften\", \\\n",
    "             \"Emotionen\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wortfelder_dict = defaultdict(def_value)\n",
    "for wortfeld in wortfelder:\n",
    "    file = \"data/Wordlists_from_fasttext/\" + wortfeld + \"_from_fasttext_cleaned.csv\"\n",
    "    wortlist = process_wordlist(file)\n",
    "    for wort in wortlist:\n",
    "        wortfelder_dict[wort] = wortfeld\n",
    "#wortfelder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wortfelder_dict[\"Glück\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/roman_corpus_lemmatisiert.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ant_narr_abstrakt\"] = 0\n",
    "df[\"ant_ind_abstrakt\"] = 0\n",
    "df[\"ant_dir_abstrakt\"] = 0\n",
    "df[\"ant_rep_abstrakt\"] = 0\n",
    "df[\"ant_free_abstrakt\"] = 0\n",
    "\n",
    "df[\"ant_narr_konkret\"] = 0\n",
    "df[\"ant_ind_konkret\"] = 0\n",
    "df[\"ant_dir_konkret\"] = 0\n",
    "df[\"ant_rep_konkret\"] = 0\n",
    "df[\"ant_free_konkret\"] = 0\n",
    "\n",
    "df[\"ant_dir_rede\"] = 0\n",
    "df[\"ant_ind_rede\"] = 0\n",
    "df[\"ant_rep\"]= 0\n",
    "df[\"ant_free\"] = 0\n",
    "df[\"ant_narr\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wortfeld in wortfelder:\n",
    "    df[\"anteil_\" + wortfeld] = 0\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstconc-Werte als Dictionary\n",
    "# the dataset used to compute the scores can be downloaded from this website: http://www.schulteimwalde.de/resources/affective-norms.html\n",
    "\n",
    "dfca = pd.read_csv(\"data/ratings_lrec16_koeper_ssiw.txt\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "dfca_dict = defaultdict(def_value)\n",
    "for i in range(len(dfca)):\n",
    "    key = dfca[\"Word\"].loc[i]\n",
    "    value = dfca[\"AbstConc\"].loc[i]\n",
    "    dfca_dict[key] = value\n",
    "#dfca_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstconc\"] = 0\n",
    "df[\"abstconc_dir\"] = 0\n",
    "df[\"abstconc_ind\"] = 0\n",
    "df[\"abstconc_rep\"] = 0\n",
    "df[\"abstconc_free\"] = 0\n",
    "df[\"abstconc_narr\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diese Schleife iteriert über alle Romane des Korpus und liest jeweils den Output aus dem Redewiedergabe-Tagger ein.\n",
    "# Anschließend wird für jede Redewiedergabe-Art der Anteil der konkreten bzw. abstrakten Wörter ermittelt.\n",
    "# Auf Basis des Datensatzes von Schulte im Walde und Köper wird zudem ein Konkretheitswert für den jeweiligen Rede-\n",
    "# wiedergabetyp ermittelt.\n",
    "# Textpassagen, die mit keiner der Redewiedergabe-Typen getaggt wurden werden als Erzählertext (\"narr\") aufgefasst.\n",
    "\n",
    "import os\n",
    "# Für jeden Roman im Korpus\n",
    "for i in tqdm(range(429, len(df))):\n",
    "    filename_dir = \"data/output_tagger/outputdir_direct/\" + df[\"filename\"].loc[i] + \".tsv\"\n",
    "    filename_ind = \"data/output_tagger/outputdir_indirect/\" + df[\"filename\"].loc[i] + \".tsv\"\n",
    "    filename_rep = \"data/output_tagger/outputdir_reported/\" + df[\"filename\"].loc[i] + \".tsv\"\n",
    "    filename_free = \"data/output_tagger/outputdir_free/\" + df[\"filename\"].loc[i] + \".tsv\"\n",
    "    \n",
    "    # einzelne Redewiedergabe dfs einlesen und mergen\n",
    "    if os.path.exists(filename_dir) and os.path.exists(filename_ind) and os.path.exists(filename_rep) and \\\n",
    "    os.path.exists(filename_free):\n",
    "        \n",
    "        df_dir = pd.read_csv(filename_dir, sep=\"\\t\").reset_index()\n",
    "        df_ind = pd.read_csv(filename_ind, sep=\"\\t\").reset_index()\n",
    "        df_merg = df_dir.merge(right=df_ind, left_index=True, right_on='index')\n",
    "        #df_merg.drop(columns=['tok_y', 'sentstart_x', \"sentstart_y\"], inplace=True)\n",
    "        df_rep = pd.read_csv(filename_rep, sep=\"\\t\").reset_index()\n",
    "        df_merg = df_merg.merge(right=df_rep, left_index =True, right_on=\"index\")\n",
    "        df_merg.drop(columns=['tok_x', 'index_y'], inplace=True)\n",
    "        df_free = pd.read_csv(filename_free, sep=\"\\t\").reset_index()\n",
    "        df_merg = df_merg.merge(right=df_free, left_index =True, right_on=\"index\")\n",
    "        df_merg.drop(columns=['tok_y', 'sentstart_y', \"index_x\"], inplace=True)\n",
    "        \n",
    "        #print(len(df_merg))\n",
    "        \n",
    "        unerwünschte_zeichen = [\".\", \",\", \";\", \"-\", \"–\", \"?\", \"!\", \"»\", \"«\", \":\"]\n",
    "        for zeichen in unerwünschte_zeichen:    \n",
    "            df_merg = df_merg[df_merg.tok_x != zeichen]\n",
    "        \n",
    "        #print(\"bereinigt\")\n",
    "        \n",
    "        df_merg = df_merg.reset_index()\n",
    "        \n",
    "        dir_cnt_konkr = 0\n",
    "        dir_cnt_abst = 0\n",
    "        \n",
    "        narr_cnt_konkr = 0\n",
    "        narr_cnt_abst = 0\n",
    "        \n",
    "        ind_cnt_konkr = 0\n",
    "        ind_cnt_abst = 0\n",
    "        \n",
    "        rep_cnt_konkr = 0\n",
    "        rep_cnt_abst = 0\n",
    "        \n",
    "        free_cnt_konkr = 0\n",
    "        free_cnt_abst = 0\n",
    "        \n",
    "        for j in range(len(df_merg)):\n",
    "            \n",
    "\n",
    "            lemma = df_merg[\"tok_x\"].loc[j]\n",
    "            # Aufgesplittet nach abstrakt/konkret + Redewiedergabe\n",
    "            \n",
    "            if df_merg[\"direct_pred\"].loc[j] == \"direct\":\n",
    "                if dfca_dict[lemma] != \"Not Present\":\n",
    "                    df[\"abstconc_dir\"].loc[i] += dfca_dict[lemma]\n",
    "                if words_dict[lemma] == \"abst\":\n",
    "                    dir_cnt_abst += 1\n",
    "                elif words_dict[lemma] == \"konkr\":\n",
    "                    dir_cnt_konkr += 1\n",
    "            \n",
    "            elif df_merg[\"indirect_pred\"].loc[j] == \"indirect\":\n",
    "                if dfca_dict[lemma] != \"Not Present\":\n",
    "                    df[\"abstconc_ind\"].loc[i] += dfca_dict[lemma]\n",
    "                if words_dict[lemma] == \"abst\":\n",
    "                    ind_cnt_abst += 1\n",
    "                elif words_dict[lemma] == \"konkr\":\n",
    "                    ind_cnt_konkr += 1\n",
    "            \n",
    "            elif df_merg[\"reported_pred\"].loc[j] == \"reported\":\n",
    "                if dfca_dict[lemma] != \"Not Present\":\n",
    "                    df[\"abstconc_rep\"].loc[i] += dfca_dict[lemma]\n",
    "                if words_dict[lemma] == \"abst\":\n",
    "                    rep_cnt_abst += 1\n",
    "                elif words_dict[lemma] == \"konkr\":\n",
    "                    rep_cnt_konkr += 1\n",
    "                    \n",
    "            \n",
    "            elif df_merg[\"freeIndirect_pred\"].loc[j] == \"freeIndirect\":\n",
    "                if dfca_dict[lemma] != \"Not Present\":\n",
    "                    df[\"abstconc_free\"].loc[i] += dfca_dict[lemma]\n",
    "                if words_dict[lemma] == \"abst\":\n",
    "                    free_cnt_abst += 1\n",
    "                elif words_dict[lemma] == \"konkr\":\n",
    "                    free_cnt_konkr += 1\n",
    "                    \n",
    "            else:\n",
    "                if dfca_dict[lemma] != \"Not Present\":\n",
    "                    df[\"abstconc_narr\"].loc[i] += dfca_dict[lemma]\n",
    "                if words_dict[lemma] == \"abst\":\n",
    "                    narr_cnt_abst += 1\n",
    "                elif words_dict[lemma] == \"konkr\":\n",
    "                    narr_cnt_konkr += 1\n",
    "                \n",
    "            \n",
    "        \n",
    "        all_words_count = len(df_merg)\n",
    "        \n",
    "        print(\"Werte normalisieren\")\n",
    "        #Werte normalisieren\n",
    "        \n",
    "        df[\"ant_narr_abstrakt\"].loc[i] = narr_cnt_abst/all_words_count\n",
    "        df[\"ant_ind_abstrakt\"].loc[i] = ind_cnt_abst/all_words_count\n",
    "        df[\"ant_dir_abstrakt\"].loc[i] = dir_cnt_abst/all_words_count\n",
    "        df[\"ant_rep_abstrakt\"].loc[i] = rep_cnt_abst/all_words_count\n",
    "        df[\"ant_free_abstrakt\"].loc[i] = free_cnt_abst/all_words_count\n",
    "\n",
    "        df[\"ant_narr_konkret\"].loc[i] = narr_cnt_konkr/all_words_count\n",
    "        df[\"ant_ind_konkret\"].loc[i] = ind_cnt_konkr/all_words_count\n",
    "        df[\"ant_dir_konkret\"].loc[i] = dir_cnt_konkr/all_words_count\n",
    "        df[\"ant_rep_konkret\"].loc[i] = rep_cnt_konkr/all_words_count\n",
    "        df[\"ant_free_konkret\"].loc[i] = free_cnt_konkr/all_words_count\n",
    "    \n",
    "        #Anteil des jeweiligen Redewiedergabe-Typs am Gesamttet\n",
    "        df[\"ant_dir_rede\"].loc[i] = df_merg['direct_pred'].value_counts()[\"direct\"]/all_words_count\n",
    "        df[\"ant_ind_rede\"].loc[i] = df_merg['indirect_pred'].value_counts()[\"indirect\"]/all_words_count\n",
    "        df[\"ant_rep\"].loc[i] = df_merg['reported_pred'].value_counts()[\"reported\"]/all_words_count\n",
    "        df[\"ant_free\"].loc[i] = df_merg['freeIndirect_pred'].value_counts()[\"freeIndirect\"]/all_words_count\n",
    "        \n",
    "        #Werte für einzelne Wortfelder normalisieren\n",
    "        for wortfeld in wortfelder:\n",
    "            df[\"anteil_\" + wortfeld].loc[i] = df[\"anteil_\" + wortfeld].loc[i]/all_words_count\n",
    "                    \n",
    "        # Abstconc\n",
    "        df[\"abstconc\"].loc[i] = df[\"abstconc\"].loc[i]/all_words_count\n",
    "        df[\"abstconc_dir\"].loc[i] = df[\"abstconc_dir\"].loc[i]/all_words_count\n",
    "        df[\"abstconc_ind\"].loc[i] = df[\"abstconc_ind\"].loc[i]/all_words_count\n",
    "        df[\"abstconc_rep\"].loc[i] = df[\"abstconc_rep\"].loc[i]/all_words_count\n",
    "        df[\"abstconc_free\"].loc[i] = df[\"abstconc_free\"].loc[i]/all_words_count\n",
    "        df[\"abstconc_narr\"].loc[i] = df[\"abstconc_narr\"].loc[i]/all_words_count\n",
    "                    \n",
    "    \n",
    "    else:\n",
    "        print(\"Datei fehlt: \" + filename_dir.split(\"/\")[2])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern als csv-Datei\n",
    "df_without_lemmas = df.copy()\n",
    "df_without_lemmas = df_without_lemmas.drop(columns=[\"all_lemmas\"])\n",
    "df_without_lemmas.to_csv(\"data/roman_korpus_word_frequencies_redewiedergabe.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
